# 第四周周记



## 排序算法



## 快排



​	有一个数组，[begin,end] ,找一个轴（一般是第一个数）作为参照数，将数组分为小于它（左）和大于它（右）两边，将当前轴的位置定下后，可以往右走，[begin,mid-1] (mid是轴的位置),可以往左走,[mid+1,end]，分别重新看成两个新数组，再不断重复，直到所有数都被放在了轴位置上。

​	快的原因：每次将一个大数组分成两个小数组，本来应该是每个数都与[begin,end]这个大数组的每个数进行比较，但分成两个小数组后，将它需要比较的范围缩小到了[begin,mid-1]或[mid+1,end]。



##  归并排序



​	将一个数组拆成两个数组，将两个数组拆成四个......最后，每个数组里都只剩下了一个数。合并原本是在同一个大数组里的小数组，由于小数组本身有序，所以在合并时只用比较两个小数组中仍未放入大数组中的第一位数即可。

  快的原因：设数组有n个数，数组的递归层数为m。从比较次数方面来看，在普通排序中，一个数要与其它所有数都比较一次，比较次数为n-1，但在归并排序中，一个数在每一层递归中最多比较一次，比较次数<=m。2^m>=n,所有m<log2(n)+1，log2(n)+1<<m，所以归并排序很快



## 插入排序

​	插入排序将一个数组的前i个数变有序的过程，将第i+1位放到[1,i+1]这个范围之间的合适位置后[1,i+1]变有序，即可将整个数组变有序。

​	但由于只比普通排序快1/2，所以提速效果不是很好。



## 计数排序

​	统计数字的出现情况，得到有多少个数是小于等于它的，最后它的位置就是它前面有多少个数（不包括自己所以-1）.

​	O(2*n+m),n是数的个数，m是最大数，很快了，但是对一些大数来说，就会变得很慢。



## 基数排序

​	基数排序是计数排序的增强版，从个位排序后再十位排序再到百位......每一位按计数排序进行排序。

​	O(n*m\*k)n是数的个数，m是最大数位，k<=10,但其实就是O(n),很快很快，毕竟不用两个数之间比较。

​	缺点：整数



# 网络爬虫



## 读取网页

从网页url中取得html，我们所需要的就是html（html文档）因为所需要的信息一般是存在html中的。



### requests库

requests可以调用requests.get(url)得到一个地址，可以再用requests.get(url).text()得到一个文本，这个文本和我们从开发者工具中看到的html差不多,当然是返回字符串的。（用get时返回状态码200就是说明成功了）



## 定位信息



### lxml.etree库

lxml.etree为我们提供了一个快速查找的方法:按路径查找。

```python
#import lxml.etree as etree
html_etree=etree.HTML(html)             #将html转化为etree树
html_etree_file=html_etree.xpath('//*[@id="content"]/div/div[1]/ol/li')#树的路径
```

我们能从网页中的开发者工具中查看每一项的xpath，就能很快的定位到该信息的位置了。

xpath还有一个很好的转换格式功能，在文本路径的末尾加(''/text()')可以转为list，("/text()")[0]可以转为字符串



### re库

re库让我们能用正则表达式来筛选信息。

```
pattern = re.compile('导演: +((\w)*[\u4E00-\u9FA5A]*(·[\u4E00-\u9FA5A]*)*( [A-Z][a-z]*)*( / )*)*')
​```
\w:所有的数字字母下划线
*:前面的字符串可以出现0-n次
[...]:匹配中间的字符
​```
```



## 防反爬

在requests时设置headers，将headers设置好浏览器、响应来源（源网页）、ip地址等

```
headers={                                 #设置请求头，不然会被拦截
    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36',
    'Referer':'https://movie.douban.com/top250'
}
proxy = {		#设一个可以用的ip
    'https':'127.0.0.1:10809'
}
html=requests.get(url=url,headers=headers,proxies=proxy).text
```



# 数据库SQL



## 连接数据库

```
MySQLdb.connect("localhost", "test", "123456", "mysql", charset='utf8' )
#第一个是主机，第二个是用户，第三个是密码，第四个是库名，charset是设置编码格式
```



## 建立表

```
# 使用cursor()方法获取操作游标 
cursor = db.cursor()

# 如果数据表已经存在使用 execute() 方法删除表。
cursor.execute("DROP TABLE IF EXISTS douban")

# 创建数据表SQL语句
sql = """CREATE TABLE douban (		#标题名及其类型
         TOP int,
         name char(250) not null,
         direct  CHAR(250) NOT NULL,
         time  char(30),
         score char(250),  
         people_num char(250),
         movie_describe text )"""

cursor.execute(sql)
```



## 插入数据

```
def IN (top,name,direct,time,score,people_num,movie_describe,db,cursor):
    sql="insert into douban(top,name,direct,time,score,people_num,movie_describe) values (%s,%s,%s,%s,%s,%s,%s)"#建立sql语句
    value=(top,name,direct,time,score,people_num,movie_describe)
    cursor.execute(sql,value)
    db.commit()
#使用的是sql语句，insert into "表名"(标题名) values(%s) 这里有点像format
#然后建立元组，将想存的数据放入
#用execute(语句,元组)即可插入
```

