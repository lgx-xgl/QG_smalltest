#  panda 使用



## 文件的输入输出

`pd.read_csv("文件",sep="分隔符（默认为，）")`

`sub.to_csv("文件",index=None（表示将行索引给忽略）)`



## panda类是怎样的东西

个人理解：panda中的Data Frame是通过索引和值构成的对象，panda同时又包含了许多方便快捷的函数,使我们面对二维数组可进行矩阵操作，并且能快捷地对数组中的数据进行清洗和填充，对数据挖掘极为友好。



## panda在线性回归中的应用

按照数据挖掘的流程看：
1.数据输入  `pd.read_csv("文件",sep="分隔符（默认为，）")`



2.数据清洗

 `train_data.dropna(inplace=True,axis=0,subset=["education","difficulty_level"]) `

将括号里的索引中有Non值的给去掉，inplace=True是将源df给替换掉，axis=0/1(选择行或列)



3.数据填充 `train_data['age']=train_data['age'].fillna(train_data['age'].mean())`

将df[索引列/行]中的non值用fillna括号中的值填充，这里是用mean即平均值来填充



4.数据转换 `train_data.loc[train_data['education'] == 'Matriculation', 'education'] = 6`

df.loc用于定位[[行]，[列]]，行是列索引education中值为Matriculation所在行，列为education



5.所需数据特征定位 predictors = [ "difficulty_level","education","gender"]

再使用df[predictors]就可以获取list中三个特征列的数据



6.不仅每个数据可以单独替换，每列也可以整列替换 sub['is_pass']=test1_target

要求：两列之间行数相同



7.导出数据 df.to_csv("文件.csv",index=None)

index即行索引，index=None是将行索引在导出时忽略掉（=non）



**察看数据 **

train_data.head(10)  #df.head(num) 显示df前num个数据



train_data.describe()  #df.describe()  显示每列的总数量（non不算）mean平均数，std标准差（算数平方根）,min最小值，max最大值，25%为1/4值...



train_data.info()  显示每列的摘要 non-null countl不是空数据的有多少,dtype 类型



msno.matrix(train_data,figsize=(14,7))

missingno是一个可视化缺失值的库,.(data frame,figsize=(x,y))  x，y是图的大小





## sklearn.linear_model(线性回归模型)

### 最小二乘法

1.建立线性回归对象 `alg = LinearRegression()`



2.建立模型 `alg.fit(train_predictors, train_target)`

(x,y) x=特征数据   y=真实结果



3.模拟出结果 `test_predictions = alg.predict(train_data[predictors].iloc[test,:])`

.predict(x)  将特征数据添加到模型中，返回预测结果



4.查看结果的R2值  
$$
R2=1-\frac{\sum_{i=0}^n(y^2-f^2)}{\sum_{i=0}^n(y^2-\hat{y}^2)}
$$
其中的y是真实值，f是预测值，$  \hat{y}  $,是实际值的平均值

alg.score(train_data[predictors],train_data['is_pass'])

(x,y)  x是特征数据  y是结果(真实值)





### 梯度下降法

1.建立线性回归对象`alg = LinearRegression(n_iter=100)` 下降次数



2.数据预处理

数据归一化 （将数据以极值为参照化成[0,1]之间的数）

数据标准化（将数据特征整体化成标准正态分布）



3..建立模型 `alg.fit(train_predictors, train_target)`

(x,y) x=特征数据   y=真实结果



4.模拟出结果 `test_predictions = alg.predict(train_data[predictors].iloc[test,:])`

.predict(x)  将特征数据添加到模型中，返回预测结果



### 归一化

利用sklearn.preprocessing库中的StandardScaler



```python
std = StandardScaler()
std.fit(X_train)
X_train_std = std.transform(X_train)
X_test_std = std.transform(X_test)
```

